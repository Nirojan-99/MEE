{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Vm4_ard_XBJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "a-8QS_eAtnix"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mPOGItJbWd-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e06048-118c-45d0-8ca9-2b6590e12f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9166245578575037\n",
            "total_predictions: 1979\n",
            "correct_predictions: 1814\n"
          ]
        }
      ],
      "source": [
        "# for post\n",
        "from nltk import ngrams\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "\n",
        "# read file\n",
        "input_file = \"/content/drive/MyDrive/final_without_token.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Extract the sentences from the DataFrame\n",
        "sentences = df[\"Sentences\"]\n",
        "\n",
        "# split the dataset into test and train\n",
        "train_sentences, test_sentences = train_test_split(sentences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set the value of N for N-gram model\n",
        "N = 5\n",
        "\n",
        "# Create a dictionary to store N-grams and their frequency counts\n",
        "ngram_counts = defaultdict(int)\n",
        "\n",
        "# remove punctuation marks\n",
        "def remove_punctuation(tokens):\n",
        "    return [token for token in tokens if token not in punctuation]\n",
        "\n",
        "# Process each sentence and count N-grams\n",
        "for sentence in train_sentences:\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tokens = remove_punctuation(tokens)\n",
        "    ngrams_list = list(ngrams(tokens, N, pad_left=True, pad_right=True))\n",
        "    for ngram in ngrams_list:\n",
        "        ngram_counts[ngram] += 1\n",
        "\n",
        "# Calculate the probabilities of each N-gram\n",
        "ngram_probabilities = defaultdict(float)\n",
        "total_counts = sum(ngram_counts.values())\n",
        "for ngram, count in ngram_counts.items():\n",
        "    ngram_probabilities[ngram] = count / total_counts\n",
        "\n",
        "# save the model\n",
        "with open('defaultdict_file_1.pkl', 'wb') as f:\n",
        "    pickle.dump(ngram_probabilities, f)\n",
        "\n",
        "# Function to predict the next word given the previous words\n",
        "def predict_next_word(prev_words):\n",
        "    prev_ngram = tuple(prev_words)\n",
        "    candidates = []\n",
        "    for ngram, prob in ngram_probabilities.items():\n",
        "        if ngram[:-1] == prev_ngram:\n",
        "            candidates.append((ngram[-1]))\n",
        "    # candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "    return candidates if candidates else None\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "for test_sentence in test_sentences:\n",
        "    tokens = nltk.word_tokenize(test_sentence)\n",
        "    tokens = remove_punctuation(tokens)\n",
        "    for i in range(len(tokens) - N):\n",
        "        prev_words = tokens[i:i+N-1]\n",
        "        next_word = tokens[i+N-1]\n",
        "        predicted_word = predict_next_word(prev_words)\n",
        "        if predicted_word != None:\n",
        "          if next_word in predicted_word:\n",
        "              correct_predictions += 1\n",
        "          total_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('total_predictions:', total_predictions)\n",
        "print('correct_predictions:', correct_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open saved model\n",
        "with open('defaultdict_file_1.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Function to predict the next word given the previous words\n",
        "def predict_next_word(prev_words):\n",
        "    prev_ngram = tuple(prev_words)\n",
        "    candidates = []\n",
        "    for ngram, prob in model.items():\n",
        "        if ngram[:-1] == prev_ngram:\n",
        "            candidates.append((ngram[-1]))\n",
        "    # candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "    return candidates if candidates else None\n",
        "\n",
        "# Function to predict the next word given the previous words\n",
        "def predict_next_word(prev_words):\n",
        "    prev_ngram = tuple(prev_words)\n",
        "    candidates = []\n",
        "    for ngram, prob in model.items():\n",
        "        if ngram[:-1] == prev_ngram:\n",
        "            candidates.append((ngram[-1]))\n",
        "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "    return candidates if candidates else None #change prob = probability\n",
        "\n",
        "# Example prediction\n",
        "prev_words = ['பிரீமியம்']\n",
        "next_word = predict_next_word(prev_words)\n",
        "\n",
        "print('Previous words:', prev_words)\n",
        "print('Predicted next word:', next_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPbSls22tzrN",
        "outputId": "aa9a8a98-657f-4861-c6da-edfc9e7c2bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous words: ['பிரீமியம்']\n",
            "Predicted next word: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for comment\n",
        "from nltk import ngrams\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "\n",
        "# read file\n",
        "input_file = \"/content/drive/MyDrive/Dataset.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Extract the sentences from the DataFrame\n",
        "sentences = df[\"COMMENTS\"]\n",
        "\n",
        "# split the dataset into test and train\n",
        "train_sentences, test_sentences = train_test_split(sentences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set the value of N for N-gram model\n",
        "N = 4\n",
        "\n",
        "# Create a dictionary to store N-grams and their frequency counts\n",
        "ngram_counts = defaultdict(int)\n",
        "\n",
        "# remove punctuation marks\n",
        "def remove_punctuation(tokens):\n",
        "    return [token for token in tokens if token not in punctuation]\n",
        "\n",
        "# Process each sentence and count N-grams\n",
        "for sentence in train_sentences:\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tokens = remove_punctuation(tokens)\n",
        "    ngrams_list = list(ngrams(tokens, N, pad_left=True, pad_right=True))\n",
        "    for ngram in ngrams_list:\n",
        "        ngram_counts[ngram] += 1\n",
        "\n",
        "# Calculate the probabilities of each N-gram\n",
        "ngram_probabilities = defaultdict(float)\n",
        "total_counts = sum(ngram_counts.values())\n",
        "for ngram, count in ngram_counts.items():\n",
        "    ngram_probabilities[ngram] = count / total_counts\n",
        "\n",
        "# Function to predict the next word given the previous words\n",
        "def predict_next_word(prev_words):\n",
        "    prev_ngram = tuple(prev_words)\n",
        "    candidates = []\n",
        "    for ngram, prob in ngram_probabilities.items():\n",
        "        if ngram[:-1] == prev_ngram:\n",
        "            candidates.append((ngram[-1]))\n",
        "    # candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "    return candidates if candidates else None\n",
        "\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "for test_sentence in test_sentences:\n",
        "    tokens = nltk.word_tokenize(test_sentence)\n",
        "    tokens = remove_punctuation(tokens)\n",
        "    for i in range(len(tokens) - N):\n",
        "        prev_words = tokens[i:i+N-1]\n",
        "        next_word = tokens[i+N-1]\n",
        "        predicted_word = predict_next_word(prev_words)\n",
        "        if predicted_word != None:\n",
        "          if next_word in predicted_word:\n",
        "              correct_predictions += 1\n",
        "          total_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('total_predictions:', total_predictions)\n",
        "print('correct_predictions:', correct_predictions)\n",
        "\n",
        "# save model\n",
        "with open('defaultdict_file_comment.pkl', 'wb') as f:\n",
        "    pickle.dump(ngram_probabilities, f)\n"
      ],
      "metadata": {
        "id": "_DuvAwZ5W5nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7124f34-9b3c-4494-909c-948041b8d547"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5136054421768708\n",
            "total_predictions: 294\n",
            "correct_predictions: 151\n"
          ]
        }
      ]
    }
  ]
}